import argparse, torch, numpy as np
from torch.utils.data import DataLoader, WeightedRandomSampler
import torch.nn.functional as F
from pathlib import Path
from tqdm import tqdm
from lerobot_dataset.pick_place_mj_builder import MjPickPlaceOfflineDataset
from models.multitask_policy import MultiTaskPolicy

NUM_PHASES = 6

class MTStateDataset(torch.utils.data.Dataset):
    def __init__(self, base):
        self.base = base
    def __len__(self): return len(self.base)
    def __getitem__(self, idx):
        it = self.base[idx]
        # Always return numpy arrays (DataLoader will keep them as np -> we convert with as_tensor later)
        return {
            "state": np.asarray(it["obs_state"], dtype=np.float32),
            "action": np.asarray(it["action"], dtype=np.float32),
            "phase_id": int(it["phase_id"])
        }

def compute_phase_counts(ds):
    counts = np.zeros(NUM_PHASES, dtype=np.int64)
    for i in range(len(ds)):
        counts[ds[i]["phase_id"]] += 1
    return counts

def cap_weights(raw, max_ratio):
    raw = raw / np.min(raw)
    raw = np.clip(raw, 1.0, max_ratio)
    raw = raw / raw.mean()
    return raw

def build_sampler(ds, counts):
    inv = 1.0 / np.maximum(counts, 1)
    inv = inv / inv.sum()
    w = np.array([inv[ds[i]["phase_id"]] for i in range(len(ds))], dtype=np.float64)
    w /= w.sum()
    return WeightedRandomSampler(w, num_samples=len(w), replacement=True)

def to_tensor(x, device):
    if isinstance(x, torch.Tensor):
        return x.to(device)
    return torch.as_tensor(x, device=device)

def main(args):
    base = MjPickPlaceOfflineDataset(args.data_root, use_paraphrase=False)
    if len(base) == 0:
        raise RuntimeError("Empty dataset at " + args.data_root)
    state_dim = base[0]["obs_state"].shape[0]
    action_dim = base[0]["action"].shape[0]
    ds = MTStateDataset(base)
    counts = compute_phase_counts(ds)
    print("Phase counts:", counts.tolist())

    if args.sample_balance:
        sampler = build_sampler(ds, counts)
        loader = DataLoader(ds, batch_size=args.batch_size, sampler=sampler)
    else:
        loader = DataLoader(ds, batch_size=args.batch_size, shuffle=True)

    raw_w = 1.0 / np.maximum(counts, 1)
    raw_w = raw_w / raw_w.sum() * NUM_PHASES

    if args.loss_balance:
        capped = cap_weights(raw_w.copy(), args.weight_cap_ratio)
        phase_weights = torch.tensor(capped, dtype=torch.float32)
        print("Raw weights:", raw_w)
        print("Capped weights:", phase_weights.numpy())
    else:
        phase_weights = None

    device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
    model = MultiTaskPolicy(state_dim, action_dim, num_phases=NUM_PHASES, hidden=args.hidden).to(device)
    optim = torch.optim.Adam(model.parameters(), lr=args.lr)

    out_dir = Path(args.out_dir)
    out_dir.mkdir(parents=True, exist_ok=True)

    best_loss = float("inf")

    for epoch in range(1, args.epochs + 1):
        model.train()
        total_losses = []
        bc_losses = []
        ph_losses = []

        for batch in tqdm(loader, desc=f"epoch {epoch}"):
            s = to_tensor(batch["state"], device)
            a = to_tensor(batch["action"], device)
            p = torch.as_tensor(batch["phase_id"], device=device, dtype=torch.long)

            pred_a, phase_logits = model(s)

            l_bc = F.mse_loss(pred_a, a)
            if phase_weights is not None:
                ce = F.cross_entropy(phase_logits, p, reduction='none')
                l_ph = (ce * phase_weights[p]).mean()
            else:
                l_ph = F.cross_entropy(phase_logits, p)

            loss = l_bc + args.phase_loss_weight * l_ph

            optim.zero_grad()
            loss.backward()
            if args.grad_clip > 0:
                torch.nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip)
            optim.step()

            total_losses.append(loss.item())
            bc_losses.append(l_bc.item())
            ph_losses.append(l_ph.item())

        tl = float(np.mean(total_losses))
        print(f"epoch {epoch} total={tl:.5f} bc={np.mean(bc_losses):.5f} phase={np.mean(ph_losses):.5f}")

        # Save each epoch
        torch.save(model.state_dict(), out_dir / f"multitask_policy_epoch{epoch}.pt")
        if tl < best_loss:
            best_loss = tl
            torch.save(model.state_dict(), out_dir / "multitask_policy.pt")
            print("Updated best model (loss {:.5f})".format(best_loss))

    print("Final best saved:", out_dir / "multitask_policy.pt")

if __name__ == "__main__":
    ap = argparse.ArgumentParser()
    ap.add_argument("--data_root", type=str, default="data/raw/mj_pick_place_v5")
    ap.add_argument("--batch_size", type=int, default=64)
    ap.add_argument("--lr", type=float, default=3e-4)
    ap.add_argument("--epochs", type=int, default=6)
    ap.add_argument("--phase_loss_weight", type=float, default=0.3)
    ap.add_argument("--hidden", type=int, default=256)
    ap.add_argument("--grad_clip", type=float, default=1.0)
    ap.add_argument("--sample_balance", action="store_true")
    ap.add_argument("--loss_balance", action="store_true")
    ap.add_argument("--weight_cap_ratio", type=float, default=20.0)
    ap.add_argument("--out_dir", type=str, default="models/ckpts_multitask_balanced_v4")
    args = ap.parse_args()
    main(args)
